# Global variables:

MODEL = CoRa_charge
OUTDIR = ./data/output/

# Sequences:

# The alphabet to use:
# DNA, RNA or Protein...

alphabet=Codon(letter=DNA)
genetic_code=Standard

input.data1=alignment(file=./data/cleaned_fasta/$(DATA).fasta, format=Fasta, sites_to_use=all, max_gap_allowed=50%, max_unresolved_allowed=100%, remove_stop_codons=yes)

input.tree1=user(file = ./data/bionj/$(DATA).AA.bionj.dnd, format = NHX)

model1 = CodonAAClustFreq(model=K80(),frequencies=F3X4,partition=(3,1,3,2,3,3,2,3,1,3,3,1,3,3,3,3,3,3,3,3))
#model1 = YN98(kappa=1, omega=1.0, frequencies=F3X4)
# Default for CodonAAClustFreq corresponding to CoRa: partition=(1,2,3,3,3,2,2,1,2,4,4,2,4,4,1,3,3,2,2,1)

root_freq1=F3X4(init=observed)

process1 = Homogeneous(model=1, tree=1, rate=1, root_freq=1)

phylo1 = Single(process=1, data=1)

# Likelihood recursion option:
# - simple: derivatives takes more time to compute, but likelihood computation is faster.
#   For big data sets, it can save a lot of memory usage too, particularly when the data are compressed.
# - double: Uses more memory and need more time to compute likelihood, due to the double recursion.
#   Analytical derivatives are however faster to compute.
# This option has no effect in the following cases:
# - Topology estimation: this requires a double recursive algorithm,
# - Optimization with a molecular clock: a simple recursion with data compression is used in this case,
#   due to the impossibility of computing analytical derivatives.
likelihood.recursion = simple

# Site compression for the simple recursion:
# - simple: identical sites are not computed twice
# - recursive: look for site patterns to save computation time during optimization, but
#   requires extra time for building the patterns.
#   This is usually the best option, particularly for nucleotide data sets.
likelihood.recursion_simple.compression = recursive

# ----------------------------------------------------------------------------------------
#                                     Optimization
# ----------------------------------------------------------------------------------------

# Should we reestimate likelihood parameters? Tree topology will not be optimized.
# (recommanded)
optimization = FullD(derivatives=Newton)

# Tell if the parameter should be transformed in order to remove constraints.
# This can improves the optimization, but might be a bit slower.
optimization.reparametrization = no

# Final optimization step, may be useful if numerical derivatives are used:
# powell or simplex or none.
optimization.final = none

# Set the quantity of output to the screen:
optimization.verbose = 3

# Parameters to ignore (for instance equilibrium frequencies)
optimization.ignore_parameters = 

# Maximum number of likelihood evaluations:
optimization.max_number_f_eval = 10000

# Precision to reach:
optimization.tolerance = 0.001 # Adjusted to match ModelOMatic's "fast" setting.

# idem for error or warning messages:
optimization.message_handler = $(OUTDIR)$(DATA).$(MODEL).messages

# A file where to dump optimization steps (a file path or std for standard output)
optimization.profiler = $(OUTDIR)$(DATA).$(MODEL).profile

# Shall we optimize tree topology as well?
optimization.topology = no

# Algorithm to use for topology estimation: only NNI for now
optimization.topology.algorithm = NNI

# NNI method: fast, better or phyml
# You should use the phyml option, since it is really more efficient!
optimization.topology.algorithm_nni.method = phyml

# Number of phyml topology movement steps before reoptimizing parameters:
optimization.topology.nstep = 4

# Shall we estimate parameters before looking for topology movements?
optimization.topology.numfirst = no

# Tolerances: These numbers should not be too low, in order to save computation
# time and also for a better topology estimation.
# The optimization.tolerance parameter will be used for the final optimization
# of numerical parameters.
#
# Tolerance for the prior-topology estimation
optimization.topology.tolerance.before = 100

# Tolerance for the during-topology estimation
optimization.topology.tolerance.during = 100

# Shall we first scale the tree before optimizing parameters? [deprecated]
optimization.scale_first = no




# Should we write the resulting tree? none or file name.
output.tree.file = $(OUTDIR)$(DATA).$(MODEL).ML.dnd
output.tree.format = Newick

# Alignment information log file (site specific rates, etc):
output.infos = $(OUTDIR)$(DATA).$(MODEL).infos

# Write numerical parameter estimated values:
output.estimates = $(OUTDIR)$(DATA).$(MODEL).params.txt

# ----------------------------------------------------------------------------------------
#                                     Bootstrap
# ----------------------------------------------------------------------------------------

bootstrap.number = 0
# Tell if numerical parameters should be kept to their initial value when bootstrapping: 
bootstrap.approximate = no
# Set this to yes for detailed output when bootstrapping. 
bootstrap.verbose = no
bootstrap.output.file = $(OUTDIR)$(DATA).$(MODEL).ML_bstrees.dnd
